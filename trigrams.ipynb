{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Third-order Letter Approximation Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading the Text\n",
    "\n",
    "Firstly the code downloads the needed texts from the specified urls.\n",
    "\n",
    "It then creates a directory if one does not exist and downloads and decodes each book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'downloads\\The_Jungle_Book.txt' exists. Overwriting...\n",
      "File 'downloads\\A_Christmas_Carol.txt' exists. Overwriting...\n",
      "File 'downloads\\Alice_in_Wonderland.txt' exists. Overwriting...\n",
      "File 'downloads\\The_Great_Gatsby.txt' exists. Overwriting...\n",
      "File 'downloads\\Moby_Dick.txt' exists. Overwriting...\n",
      "All books have been downloaded and saved in the 'downloads' directory.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "# For the opening and fetching of URLS https://docs.python.org/3/library/urllib.request.html\n",
    "import urllib.request\n",
    "# For creating and managing directories https://docs.python.org/3/library/os.html\n",
    "import os  \n",
    "\n",
    "# Define URLs for the chosen Books, BookName:BookURL\n",
    "urls = {\n",
    "    \"The Jungle Book\": \"https://www.gutenberg.org/cache/epub/236/pg236.txt\",\n",
    "    \"A Christmas Carol\": \"https://www.gutenberg.org/cache/epub/46/pg46.txt\",\n",
    "    \"Alice in Wonderland\": \"https://www.gutenberg.org/cache/epub/11/pg11.txt\",\n",
    "    \"The Great Gatsby\": \"https://www.gutenberg.org/cache/epub/64317/pg64317.txt\",\n",
    "    \"Moby Dick\": \"https://www.gutenberg.org/cache/epub/2701/pg2701.txt\"\n",
    "}\n",
    "\n",
    "# Create a directory for downloads if it doesn't exist\n",
    "download_dir = \"downloads\"\n",
    "\n",
    "# IF the directory does not allready exist create it\n",
    "if not os.path.exists(download_dir):\n",
    "    print(f\"Directory '{download_dir}' not found. Creating it...\")\n",
    "    os.makedirs(download_dir)\n",
    "\n",
    "# Dictionary to store the content of each book\n",
    "books_content = {}\n",
    "\n",
    "# Loop through each URL and fetch the content of each page\n",
    "for book, url in urls.items():\n",
    "    # Combine the directory path with the file name after it has been correctly formatted\n",
    "    file_path = os.path.join(download_dir, f\"{book.replace(' ', '_')}.txt\")\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Overite file if it exists with the newer version\n",
    "        print(f\"File '{file_path}' exists. Overwriting...\")\n",
    "    else:\n",
    "        # Else create a new one\n",
    "        print(f\"File '{file_path}' does not exist. Downloading...\")\n",
    "    \n",
    "    # Fetch and decode the content\n",
    "    # Open Url and fetch respones\n",
    "    response = urllib.request.urlopen(url)\n",
    "    # read and decode response to readable utf-8\n",
    "    content = response.read().decode('utf-8')\n",
    "\n",
    "    # Store downloaded content into a Dictionary\n",
    "    books_content[book] = content\n",
    "\n",
    "    # Save the content to the file overwriting if it allready exists\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(content)\n",
    "\n",
    "print(f\"All books have been downloaded and saved in the '{download_dir}' directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Processing the Text\n",
    "\n",
    "With specified start and end markers that are present in all project gutenberg files the required text is extracted and processed into all caps and only using A-Z characters as well as the space and period characters.\n",
    "\n",
    "The processed texts are then saved into a processed directory as individual files wile not completely necessary it makes it easier to inspect the results individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Text for The Jungle Book...\n",
      "Processing Text for A Christmas Carol...\n",
      "Processing Text for Alice in Wonderland...\n",
      "Processing Text for The Great Gatsby...\n",
      "Processing Text for Moby Dick...\n",
      "All books have been processed and saved in the 'downloads/processed' directory.\n"
     ]
    }
   ],
   "source": [
    "# For finding and replacing unwanted characters and sections of the text https://docs.python.org/3/library/re.html\n",
    "import re\n",
    "\n",
    "def clean_text(raw_text):\n",
    "    \n",
    "    # Identify the main text content (strip preamble and postamble)\n",
    "    # All Gutenberg EBooks have this section in their books making it easy to trim the start and end\n",
    "    start_marker = \"*** START OF THIS PROJECT GUTENBERG EBOOK\"\n",
    "    end_marker = \"*** END OF THIS PROJECT GUTENBERG EBOOK\"\n",
    "    \n",
    "    # Extract content between the markers\n",
    "    # Start Extraction from\n",
    "    start_index = raw_text.find(start_marker)\n",
    "    # End Extraction at\n",
    "    end_index = raw_text.find(end_marker)\n",
    "    \n",
    "    # If the markers exist in the text\n",
    "    if start_index != -1 and end_index != -1:\n",
    "        # Extract the text between the markers\n",
    "        text = raw_text[start_index + len(start_marker):end_index]\n",
    "    else:\n",
    "        # If the markers are not found use the entire text\n",
    "        text = raw_text \n",
    "    \n",
    "    # Remove unwanted characters and convert to uppercase\n",
    "    # Convert all text to upper case and then remove any character that is not A-Z a \" \" or a \".\"\n",
    "    cleaned_text = re.sub(r\"[^A-Z\\s\\.]\", \"\", text.upper())\n",
    "    # Return the cleaned up text\n",
    "    return cleaned_text\n",
    "\n",
    "# Dictionary for processed books\n",
    "processed_books = {}\n",
    "\n",
    "# For each unprocessed book\n",
    "for book, raw_text in books_content.items():\n",
    "    # Log the processing og the book\n",
    "    print(f\"Processing Text for {book}...\")\n",
    "\n",
    "    # Store the processed text in the processed dictionary\n",
    "    processed_books[book] = clean_text(raw_text)\n",
    "\n",
    "# Save processed text locally in a processed folder inside the download directory\n",
    "processed_dir = os.path.join(download_dir, \"processed\")\n",
    "# Avoids errors if the directory allready exists\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# For each processed book\n",
    "for book, content in processed_books.items():\n",
    "    # save in the correct directory with the correctly formatted filename\n",
    "    file_path = os.path.join(processed_dir, f\"{book.replace(' ', '_')}_processed.txt\")\n",
    "    # Write to the file\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(content)\n",
    "\n",
    "# Log task completion to the console\n",
    "print(\"All books have been processed and saved in the 'downloads/processed' directory.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
